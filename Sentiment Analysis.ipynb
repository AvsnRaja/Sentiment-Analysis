{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deploy_Team.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"QKLZJZO9H3LE","executionInfo":{"elapsed":23444,"status":"ok","timestamp":1631714355189,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"},"user_tz":-330},"outputId":"9ec3fe98-06ef-4fba-a4fc-ea37dd026984"},"source":["!pip install streamlit"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting streamlit\n","  Downloading streamlit-0.88.0-py2.py3-none-any.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n","Collecting blinker\n","  Downloading blinker-1.4.tar.gz (111 kB)\n","\u001b[K     |████████████████████████████████| 111 kB 64.6 MB/s \n","\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.7.0-py2.py3-none-any.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 57.8 MB/s \n","\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n","Collecting base58\n","  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n","Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Collecting watchdog\n","  Downloading watchdog-2.1.5-py3-none-manylinux2014_x86_64.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n","Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n","Collecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 85.6 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n","Collecting validators\n","  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.7.4.3)\n","Collecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n","Collecting ipykernel>=5.1.2\n","  Downloading ipykernel-6.4.1-py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 83.9 MB/s \n","\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n","Requirement already satisfied: importlib-metadata<5 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.6.4)\n","Collecting ipython<8.0,>=7.23.1\n","  Downloading ipython-7.27.0-py3-none-any.whl (787 kB)\n","\u001b[K     |████████████████████████████████| 787 kB 79.0 MB/s \n","\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.2)\n","Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.12.3)\n","Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.5.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.20-py3-none-any.whl (370 kB)\n","\u001b[K     |████████████████████████████████| 370 kB 48.4 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.2.1)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.7.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.11.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.0.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n","Building wheels for collected packages: blinker\n","  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=27d58cbc70ca1b5a25ce7ecbd50f651ea4a444b16ce873933e9249631378b794\n","  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n","Successfully built blinker\n","Installing collected packages: prompt-toolkit, ipython, ipykernel, smmap, gitdb, watchdog, validators, pydeck, gitpython, blinker, base58, streamlit\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.27.0 which is incompatible.\u001b[0m\n","Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.18 ipykernel-6.4.1 ipython-7.27.0 prompt-toolkit-3.0.20 pydeck-0.7.0 smmap-4.0.0 streamlit-0.88.0 validators-0.18.2 watchdog-2.1.5\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","ipykernel","prompt_toolkit"]}}},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSqLjjmUTxc-","executionInfo":{"status":"ok","timestamp":1631714446874,"user_tz":-330,"elapsed":62250,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"ce3355b5-e173-4e2e-fb80-9d9b4a0f191a"},"source":["!pip install pyngrok==4.1.1\n","!pip install transformers\n","!pip install selenium\n","!pip install yfinance\n","\n","!apt-get update # to update ubuntu to correctly run apt install\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok==4.1.1\n","  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15984 sha256=e54fe582bc4378fec35ee8bda28352ffccb46bae6cda354946ea7383ea31b546\n","  Stored in directory: /root/.cache/pip/wheels/b1/d9/12/045a042fee3127dc40ba6f5df2798aa2df38c414bf533ca765\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-4.1.1\n","Collecting transformers\n","  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 29.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 20.2 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n","Collecting selenium\n","  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n","\u001b[K     |████████████████████████████████| 904 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n","Installing collected packages: selenium\n","Successfully installed selenium-3.141.0\n","Collecting yfinance\n","  Downloading yfinance-0.1.63.tar.gz (26 kB)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n","Collecting lxml>=4.5.1\n","  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 11.2 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n","Building wheels for collected packages: yfinance\n","  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23918 sha256=a18ac8c72b73f697c36770a5583d9fbd6a0e183e5c52a86457f25a2de93a503b\n","  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n","Successfully built yfinance\n","Installing collected packages: lxml, yfinance\n","  Attempting uninstall: lxml\n","    Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","Successfully installed lxml-4.6.3 yfinance-0.1.63\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [717 kB]\n","Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n","Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,324 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,799 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [567 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,760 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [600 kB]\n","Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [921 kB]\n","Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n","Fetched 13.6 MB in 4s (3,216 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 89 not upgraded.\n","Need to get 91.8 MB of archives.\n","After this operation, 315 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 92.0.4515.159-0ubuntu0.18.04.1 [1,124 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 92.0.4515.159-0ubuntu0.18.04.1 [81.7 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 92.0.4515.159-0ubuntu0.18.04.1 [4,026 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 92.0.4515.159-0ubuntu0.18.04.1 [4,902 kB]\n","Fetched 91.8 MB in 6s (16.1 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 148492 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_92.0.4515.159-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: use options instead of chrome_options\n","  app.launch_new_instance()\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1tSnq8nUO7f","executionInfo":{"status":"ok","timestamp":1631714446876,"user_tz":-330,"elapsed":39,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"ab45e152-bff8-4846-ec74-52737d378089"},"source":["%%writefile app.py\n","import pandas as pd\n","import string\n","import re\n","from nltk.corpus import stopwords\n","import numpy as np\n","import nltk\n","from selenium import webdriver\n","import time\n","import yfinance as yf\n","from transformers import pipeline\n","import streamlit as st\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","from collections import Counter\n","from PIL import Image\n","from wordcloud import WordCloud, STOPWORDS\n","\n","# Streamlit Deployment Code\n","\n","companies=['None','01:INFOSYS', '02:TCS', '03:RELIANCE INDUSTRIES', '04:ICICI BANK' , '05:HDFC Bank', '06:HDFC', '07:BHARTI AIRTEL' ,  '08:Wipro' ,\n","           '09:SBI' ,'10:Yes Bank' , '11:Tata Motors','12:Vodafone Idea','13:PNB', '14:MARUTI SUZUKI','15:ONGC', '16:TATA STEEL', '17:NTPC']\n","\n","st.set_page_config(page_title=\"NLP applications in Finance\", page_icon=None, layout='wide', initial_sidebar_state='expanded')\n","image = Image.open('/content/IMG2.png')\n","st.image(image, use_column_width=True)\n","\n","\n","st.sidebar.subheader(\"About us\")\n","#st.sidebar.title(\"About us\")\n","st.sidebar.write('''\n","Innodatatics is actively transformed by its highly extreme entities with various decades of realm \n","expertise among its representatives. Our R&D team advances to conceive by collaborating with its alma maters \n","in finding solution industry-complicated issues.''')\n","\n","st.sidebar.subheader(\"Project\")\n","st.sidebar.write(\"Measuring Impact of Financial News on Stock Market\")\n","select = st.sidebar.selectbox( \"Choose a company?\",(companies))\n","st.sidebar.subheader(\"Contact us\")\n","st.sidebar.write(\"Innodatatics Inc\")\n","st.sidebar.write(\"[Website](https://innodatatics.ai)\")\n","st.sidebar.write(\"© Copyrights 2021 Innodatatics\")\n","\n","if select=='None':\n","  st.write(\"You haven't selected any company yet\")\n","  \n","else:\n","  chrome_options = webdriver.ChromeOptions()\n","  chrome_options.add_argument('--headless')\n","  chrome_options.add_argument('--no-sandbox')\n","  chrome_options.add_argument('--disable-dev-shm-usage')\n","  driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n","\n","  st.write(f\"You have selected: {select[3:]}\")\n","  \n","  x=int(select[:2])\n","  company={ 1: ['INFOSYS','INFY.NS'], 2:['TCS','TCS.NS'] , 3: ['RELIANCE INDUSTRIES','RELIANCE.NS'],\n","  4: ['ICICI BANK','ICICIBANK.NS'] , 5: ['HDFC BANK','HDFCBANK.NS'], 6: ['HDFC','HDFC.NS'],\n","  7:['BHARTI AIRTEL','BHARTIARTL.NS'],  8: ['Wipro','WIPRO.NS'], 9: ['SBI','SBIN.NS'],\n","  10: ['Yes Bank','YESBANK.NS'],11:['Tata Motors','TATAMOTORS.NS'],12:['Vodafone Idea','IDEA.NS'],\n","  13:['PNB','PNB.NS'], 14: ['MARUTI SUZUKI','MARUTI.NS'],15:['ONGC','ONGC.NS'],\n","  16: ['TATA STEEL','TATASTEEL.NS'], 17: ['NTPC','NTPC.NS'] }\n","\n","  company_name=company[x][0]\n","  company_stock_code=company[x][1]\n","\n","  url='https://www.livemint.com/'\n","\n","  driver.get(url)\n","  driver.find_element_by_class_name(\"iconSprite\").click()\n","  driver.find_element_by_name(\"searchParameter\").send_keys(company_name)\n","  driver.find_element_by_name(\"btnSearch\").click()\n","\n","  for i in range(0,40,1):\n","      driver.execute_script(\"window.scrollBy(0,750)\",\"\")\n","      time.sleep(1)\n","\n","  # Extracting Headlines\n","  list1=driver.find_elements_by_class_name(\"headline\")\n","  list1=[list1[i].text for i in range(len(list1))]\n","\n","  # Extarcting dates\n","  dates=driver.find_elements_by_css_selector(\".date >span\")\n","\n","  list2=[]\n","  count=0\n","  for date in dates:\n","      id1=date.get_attribute(\"id\")\n","      search=driver.find_element_by_id(id1)\n","      x=search.get_attribute(\"data-updatedtime\")\n","      list2.append(x)\n","      count+=1\n","      # As extra links get attached for dates attributing\n","      # so making an codition to limit those dates to only number of headlines extracted\n","      if count==(len(list1)):\n","          break\n","\n","  list2=[str(list2[i]) for i in range(len(list2))]\n","  list3=[list2[i][:10] for i in range(len(list2))]\n","\n","\n","  news_data=pd.DataFrame(columns=[\"Date\",\"Title\"])\n","  news_data[\"Date\"]=list3\n","  news_data[\"Title\"]=list1\n","    \n","  #st.write(news_data.head())\n","  #st.write(news_data.tail())  \n","\n","  #### Yahoo Finance Data\n","  ## company stock price data\n","  \n","  fin_data = yf.download(company_stock_code, start=list3[-1], end=list3[0])\n","  fin_data =fin_data[[\"Close\"]]\n","      \n","  fin_data=fin_data.reset_index()\n","  fin_data['Date']=[str(fin_data['Date'][i].date()) for  i in range(len(fin_data))]\n","\n","  #st.write(fin_data.head())\n","  #st.write(fin_data.tail())\n","\n","  ##\n","  data=news_data\n","  data1=fin_data\n","\n","  data=data[::-1].reset_index()\n","  data.drop(columns=['index'],axis=True,inplace=True)\n","  ##\n","\n","  # Cleaning of Data\n","  def clean_data(data):\n","    \n","    list1=[]\n","    list1=data['Title']\n","    import re\n","    import nltk\n","    nltk.download('stopwords')\n","    \n","    for i in range(len(list1)):               \n","        tokens = list1[i].split()\n","        # prepare regex for char filtering\n","        re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n","        # remove punctuation from each word\n","        tokens = [re_punc.sub('', w) for w in tokens]\n","        # remove remaining tokens that are not alphabetic\n","        tokens = [word for word in tokens if word.isalpha()]\n","        # filter out stop words\n","        stop_words = set(stopwords.words('english'))\n","        tokens = [w for w in tokens if not w in stop_words]\n","        # filter out short tokens\n","        tokens = [word for word in tokens if len(word) > 1]\n","        list1[i] = ' '.join(tokens)\n","    data['Title']=list1\n","    return data\n","\n","    data=clean_data(data)\n","      \n","\n","\n","  # MODEL:\n","\n","  def model_sentiment(data):\n","      classifier = pipeline('sentiment-analysis', model=\"ProsusAI/finbert\")\n","      list3=[]\n","      for i in range(len(data['Title'])):\n","          a=(classifier(data['Title'][i]))\n","          a=a[0]\n","          a=list(a.values())[0]\n","          label_f={'positive':1,'negative':2,'neutral':0}\n","          list3.append(label_f[a])\n","      data['1day_sentiment']=list3\n","      del list3\n","      return (data)\n","    \n","\n","  #As data has many news articles published in a day we need to aggregate all the news article on a particular day.\n","  data=model_sentiment(data)\n","\n","  aggregation_functions = {'Title': 'first', '1day_sentiment': 'max'}\n","  data = data.groupby(data['Date']).aggregate(aggregation_functions)\n","  data.reset_index(inplace=True)\n","\n","  data['1day_sentiment']=data['1day_sentiment'].astype('float')\n","\n","  # Calculating Exponential Weighted average for 3,7,15 days sentiments\n","  data['3day_sentiment'] = round(data['1day_sentiment'].ewm(span=3).mean())\n","  data['7day_sentiment'] = round(data['1day_sentiment'].ewm(span=7).mean())\n","  data['15day_sentiment'] = round(data['1day_sentiment'].ewm(span=15).mean())\n","\n","  data2=data.drop(columns=['Title'],axis=1)# Dropping Title as for further analysis, it's not required.\n","\n","  # Labelling the data for better understanding\n","  \n","  label={0: 'Neutral',1:'Positive',2:'Negative'}\n","  data2['1day_sentiment']=[label[data2['1day_sentiment'][i]]for i in range(len(data2))]\n","  data2['3day_sentiment']=[label[data2['3day_sentiment'][i]]for i in range(len(data2))]\n","  data2['7day_sentiment']=[label[data2['7day_sentiment'][i]]for i in range(len(data2))]\n","  data2['15day_sentiment']=[label[data2['15day_sentiment'][i]]for i in range(len(data2))]\n","  \n","  # Calculating Percentage change\n","\n","  data1['perc_change1'] =data1['Close'].pct_change(periods=1)*100\n","  list1=list(data1.perc_change1)\n","  list1.append(np.nan)\n","  del list1[0] # for 1 forward window del 1st value\n","  data1['rolling_perc']=list1\n","  data1.drop(columns=['perc_change1'],axis=1,inplace=True)\n","\n","  # Converting dates from string to date format for merging two columns:\n","\n","  data2['Date']=pd.to_datetime(data2['Date'],format='%Y-%m-%d')\n","  data1['Date']=pd.to_datetime(data1['Date'],format='%Y-%m-%d')\n","\n","  # Merging the data frame per date column in a sequential order\n","  merge = pd.merge_asof(data2, data1, on='Date')\n","\n","  # Last rows of the dataframe will not have any percentage values as there is no new data is available. So saving those indexes in list to avoid error in \n","  # future analysis.\n","\n","  null_perc_change= list(np.where(merge['rolling_perc'].isnull())[0])\n","\n","\n","  # Business Problem Analysis\n","  # A. Sentiment Meter\n","  # B. Price Movement analysis based on Sentiment meter\n","  # To Study how many investment oppurtunities were profitable, loss making\n","  data4=pd.DataFrame(columns=[\"Description\",\"Total Opportunities\",\"Profit(%)\",\"Loss(%)\",\"No Profit No Loss(%)\"])\n","  desc=[]\n","  total1=[]\n","  profit1=[]\n","  loss1=[]\n","  npnl1=[]\n","  #These are done to compute how sentiment rolling days is behaving with actual price\n","  col=[1,2,3,4]\n","  for j in col:\n","    #print(j)\n","    profit=0\n","    loss=0\n","    npnl=0\n","    for i in range(len(merge)):\n","      if i in null_perc_change:\n","        continue\n","      #print(i)\n","      if merge.iloc[i,j]=='Negative' and  merge.iloc[i,6]<0:\n","        profit+=1\n","      elif merge.iloc[i,j]=='Negative' and  merge.iloc[i,6]>0:\n","        loss+=1   \n","      elif merge.iloc[i,j]=='Positive' and  merge.iloc[i,6]>0:\n","        profit+=1\n","      elif merge.iloc[i,j]=='Positive' and  merge.iloc[i,6]<0:\n","        loss+=1\n","      if merge.iloc[i,j]=='Neutral':\n","        npnl+=1\n","    total= profit + loss +npnl\n","    desc.append(j)\n","    total1.append(total)\n","    profit1.append(profit/total*100)\n","    loss1.append(loss/total*100)\n","    npnl1.append(npnl/total*100)\n","\n","  #Summarizing the dataframes\n","  data4[\"Description\"]=[\"Rolling 1 day-News Day Event\",\"Rolling 3 day-News Day Event\",\"Rolling 7 day-News Day Event \",\"Rolling 15 day-News Day Event\"]\n","  data4[\"Total Opportunities\"]=total\n","  data4['Profit(%)']=profit1 \n","  data4['Loss(%)']=loss1\n","  data4['No Profit No Loss(%)']=npnl1\n","\n","  data_1=data.drop(columns=[\"Title\"],axis=1)\n","  data_f1=data_1.iloc[len(data_1)-1,]\n","  label={0.0: 'Neutral',1.0:'Positive',2.0:'Negative'}\n","  f_data=pd.DataFrame(columns=[\"Description\", \"Sentiment\"])\n","  f_data[\"Description\"]=[\"Rolling 1 day-News Day Event\",\"Rolling 3 day-News Day Event\",\"Rolling 7 day-News Day Event \",\"Rolling 15 day-News Day Event\"]\n","  f_data[\"Sentiment\"]=[label[data_f1[i]] for i in range(1,len(data_f1),1)]\n","\n","  # PIE CHART CODE\n","\n","  labels = ['Neutral', 'Positive','Negative']\n","  sizes = [data['1day_sentiment'].value_counts()[0],data['1day_sentiment'].value_counts()[1],data['1day_sentiment'].value_counts()[2]]\n","  # Plot\n","  fig, ax = plt.subplots(figsize=(4,4))\n","  #st.subheader('News Classification based on sentiment Analysis')\n","  ax.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=False, startangle=140)\n","  plt.title('News type based on sentiment Analysis')\n","  buf1 = BytesIO()\n","  fig.savefig(buf1, format=\"png\")\n","  \n","  # Word CLoud\n","  words=list(data['Title'])\n","  vocab=Counter()          \n","  vocab1=[]\n","  #             \n","  for i in range(len(words)):\n","    tokens=words[i].split()\n","    for j in tokens:\n","        vocab1.append(j)\n","\n","  vocab.update(vocab1)\n","  vocab.most_common(50)\n","\n","  other_stopwords_to_remove = ['\\\\n', 'n', '\\\\', '>', 'nLines', 'nI',\"n'\", \"hi\"]\n","  STOPWORDS = STOPWORDS.union(set(other_stopwords_to_remove))\n","  stopwords = set(STOPWORDS)\n","  text = str(vocab)\n","  wordcloud = WordCloud(width = 1800, height = 1800, background_color ='white', \n","                        max_words=200, stopwords = stopwords, min_font_size = 10).generate(text)\n","\n","  fig, ax = plt.subplots(figsize=(4,4))\n","  ax.imshow(wordcloud, interpolation='bilinear')\n","  plt.title(\"News based word cloud\")\n","  plt.axis(\"off\")\n","  \n","  buf2 = BytesIO()\n","  fig.savefig(buf2, format=\"png\")\n","  images = [buf1,buf2]\n","  st.image(images, use_column_width=False)\n","\n","  st.subheader(\"Current News Based Sentiment Report\")\n","  st.write(\"Last News Day Recoded : \",data_f1[0])\n","  f_data.set_index('Description')\n","  st.write(f_data)\n","\n","  st.subheader(\"Back Testing News Based Investment Oppurtunities\")\n","  st.write(\"We have back-tested news based investment oppurtunities assuming ***Square off the trade within  next trading day***\")\n","  st.write(data4)\n","  data4.set_index(\"Description\")\n","  a=data4['Profit(%)'].idxmax()\n","  pd.options.display.float_format = '{:,.2f}'.format \n","  # Summary dataframe providing details about how the \n","  summary=pd.DataFrame(columns=[\"Description\",\"Event Name\",\"Value\"])\n","  summary['Description']=[\"Most profitable news event\",\"Most loss incurred for the news event\"]\n","  summary[\"Event Name\"]=[data4[\"Description\"][data4['Profit(%)'].idxmax()],data4[\"Description\"][data4['Loss(%)'].idxmax()]]\n","  summary[\"Value\"]=[data4['Profit(%)'].max(),data4['Loss(%)'].max()]\n","  st.write(summary)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJg1Cj5uI3mk","executionInfo":{"status":"ok","timestamp":1631714446877,"user_tz":-330,"elapsed":33,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"e9614fe7-28dc-4f7d-92be-9cef639b1e2c"},"source":["!ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["app.py\tIMG2.png  sample_data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DH29QDMAI9F_","executionInfo":{"status":"ok","timestamp":1631714453316,"user_tz":-330,"elapsed":6464,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"57ccbe1a-8674-41d2-a685-30460d59368d"},"source":["!ngrok authtoken ./ngrok authtoken 1xHDQ0ZVGhTEWf2WvFJWvwgCW9U_7MWDgdeCydvLzgnNvBSa4"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["NAME:\n","   authtoken - save authtoken to configuration file\n","\n","USAGE:\n","   ngrok authtoken [command options] [arguments...]\n","\n","DESCRIPTION:\n","   The authtoken command modifies your configuration file to include\n","   the specified authtoken. By default, this configuration file is located\n","   at $HOME/.ngrok2/ngrok.yml\n","\n","   The ngrok.com service requires that you sign up for an account to use\n","   many advanced service features. In order to associate your client with\n","   an account, it must pass a secret token to the ngrok.com service when it\n","   starts up. Instead of passing this authtoken on every invocation, you may\n","   use this command to save it into your configuration file so that your\n","   client always authenticates you properly.\n","\n","EXAMPLE:\n","    ngrok authtoken BDZIXnhJt2HNWLXyQ5PM_qCaBq0W2sNFcCa0rfTZd\n","\n","OPTIONS:\n","   --config \t\tsave in this config file, default: ~/.ngrok2/ngrok.yml\n","   --log \"false\"\tpath to log file, 'stdout', 'stderr' or 'false'\n","   --log-format \"term\"\tlog record format: 'term', 'logfmt', 'json'\n","   --log-level \"info\"\tlogging level\n","\n","ERROR:  You must pass a single argument, the authtoken to save to configuration file.\n"]}]},{"cell_type":"code","metadata":{"id":"SlVzkv19JAkv","executionInfo":{"status":"ok","timestamp":1631714453317,"user_tz":-330,"elapsed":30,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}}},"source":["from pyngrok import ngrok"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"oI3_W0t0JCJx","executionInfo":{"status":"ok","timestamp":1631714453318,"user_tz":-330,"elapsed":28,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}}},"source":["!streamlit run app.py &>/dev/null&"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pg5J77MnJEyi","executionInfo":{"status":"ok","timestamp":1631714453319,"user_tz":-330,"elapsed":27,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"a9112da7-da85-4619-f5a0-393c0a0cb529"},"source":["!pgrep streamlit"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2192\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrSXfx2SJGpU","executionInfo":{"status":"ok","timestamp":1631714453982,"user_tz":-330,"elapsed":680,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"bfa1f795-2bd3-4546-a2ef-34baa384067e"},"source":["!ngrok http\t./ngrok http 8501"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["NAME:\n","   http - start an HTTP tunnel\n","\n","USAGE:\n","   ngrok http [command options] [arguments...]\n","\n","DESCRIPTION:\n","   Starts a tunnel listening for HTTP/HTTPS traffic with a specific hostname.\n","   The HTTP Host header on incoming public requests is inspected to\n","   determine which tunnel it matches.\n","\n","   HTTPS endpoints terminate TLS traffic at the ngrok server using the\n","   ngrok.io certificates. The decrypted, HTTP traffic is then forwarded\n","   through the secure tunnel and then to your local server. If you don't want\n","   your TLS traffic to terminate at the ngrok server, use a TLS or TCP tunnel.\n","\n","EXAMPLES:\n","   ngrok http 8080                      # forward ngrok.io subdomain to port 80\n","   ngrok http example.com:9000          # forward traffic to example.com:9000\n","   ngrok http -subdomain=bar 80         # request subdomain name: 'bar.ngrok.io'\n","   ngrok http -hostname=ex.com 1234     # request tunnel 'ex.com' (DNS CNAME)\n","   ngrok http -auth='falken:joshua' 80  # enforce basic auth on tunnel endpoint\n","   ngrok http -host-header=ex.com 80    # rewrite the Host header to 'ex.com'\n","   ngrok http file:///var/log           # serve local files in /var/log\n","   ngrok http https://localhost:8443    # forward to a local https server\n","\n","OPTIONS:\n","   --auth \t\tenforce basic auth on tunnel endpoint, 'user:password'\n","   --authtoken \t\tngrok.com authtoken identifying a user\n","   --bind-tls \"both\"\tlisten for http, https or both: true/false/both\n","   --config\t\tpath to config files; they are merged if multiple\n","   --host-header \tset Host header; if 'rewrite' use local address hostname\n","   --hostname \t\thost tunnel on custom hostname (requires DNS CNAME)\n","   --inspect\t\tenable/disable http introspection\n","   --log \"false\"\tpath to log file, 'stdout', 'stderr' or 'false'\n","   --log-format \"term\"\tlog record format: 'term', 'logfmt', 'json'\n","   --log-level \"info\"\tlogging level\n","   --region \t\tngrok server region [us, eu, au, ap, sa, jp, in] (default: us)\n","   --subdomain \t\thost tunnel on a custom subdomain\n","\n","ERROR:  You must specify a single argument: a port or address to tunnel to.\n","ERROR:  You specified 3 arguments: [./ngrok http 8501]\n","ERROR:  For example, to expose port 80, run 'ngrok http 80'.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Bs3ZwvJhJJWH","executionInfo":{"status":"ok","timestamp":1631714454783,"user_tz":-330,"elapsed":805,"user":{"displayName":"Varun Sawhney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhPvZJdjM23ll-03twKP_bUAylK32Cr42hl5N_Dg=s64","userId":"13487030009114513045"}},"outputId":"498d35bc-2460-4980-a852-0027d7cfa249"},"source":["public_url = ngrok.connect(port='8501')\n","public_url"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'http://d6d5-35-247-101-82.ngrok.io'"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"NHGxxP2lJLjA"},"source":["!kill 265"],"execution_count":null,"outputs":[]}]}